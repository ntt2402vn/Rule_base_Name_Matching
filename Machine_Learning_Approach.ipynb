{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33835446",
   "metadata": {},
   "source": [
    "# Typos Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7731d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "\n",
    "df = pd.read_csv('typos_dataset.csv')\n",
    "\n",
    "# Remove special characters\n",
    "def remove_special_chars(text):\n",
    "    return re.sub(r'[^\\w\\s.]', '', text)\n",
    "\n",
    "df['fullname'] = df['fullname'].apply(lambda x: remove_special_chars(x))\n",
    "df['fullname'] = df['fullname'].apply(lambda x: x.lower())\n",
    "df['firstname'] = df['firstname'].apply(lambda x: x.lower() if not pd.isna(x) else x)\n",
    "df['firstname'] = df['firstname'].str.replace('.', '', regex=False)\n",
    "df['firstname'] = df['firstname'].apply(lambda x: remove_special_chars(x))\n",
    "df['lastname'] = df['lastname'].apply(lambda x: x.lower() if not pd.isna(x) else x)\n",
    "df['lastname'] = df['lastname'].str.replace('.', '', regex=False)\n",
    "df['lastname'] = df['lastname'].apply(lambda x: remove_special_chars(x))\n",
    "\n",
    "# Generate random list of 100 IDs\n",
    "training_ids = [17,\n",
    "713,\n",
    "703,\n",
    " 30,\n",
    " 45,\n",
    " 51,\n",
    " 52,\n",
    " 55,\n",
    " 70,\n",
    " 71,\n",
    " 85,\n",
    " 95,\n",
    " 97,\n",
    " 128,\n",
    " 134,\n",
    " 137,\n",
    " 144,\n",
    " 148,\n",
    " 163,\n",
    " 185,\n",
    " 189,\n",
    " 192,\n",
    " 196,\n",
    " 198,\n",
    " 200,\n",
    " 221,\n",
    " 228,\n",
    " 229,\n",
    " 242,\n",
    " 253,\n",
    " 254,\n",
    " 257,\n",
    " 258,\n",
    " 269,\n",
    " 271,\n",
    " 295,\n",
    " 316,\n",
    " 337,\n",
    " 338,\n",
    " 341,\n",
    " 352,\n",
    " 362,\n",
    " 363,\n",
    " 364,\n",
    " 369,\n",
    " 373,\n",
    " 385,\n",
    " 388,\n",
    " 400,\n",
    " 405,\n",
    " 410,\n",
    " 411,\n",
    " 413,\n",
    " 420,\n",
    " 428,\n",
    " 439,\n",
    " 443,\n",
    " 453,\n",
    " 457,\n",
    " 478,\n",
    " 482,\n",
    " 498,\n",
    " 500,\n",
    " 518,\n",
    " 523,\n",
    " 530,\n",
    " 531,\n",
    " 537,\n",
    " 541,\n",
    " 557,\n",
    " 563,\n",
    " 564,\n",
    " 579,\n",
    " 580,\n",
    " 584,\n",
    " 592,\n",
    " 606,\n",
    " 609,\n",
    " 641,\n",
    " 659,\n",
    " 662,\n",
    " 664,\n",
    " 668,\n",
    " 675,\n",
    " 677,\n",
    " 679,\n",
    " 683,\n",
    " 690,\n",
    " 694,\n",
    " 707,\n",
    " 710,\n",
    " 716,\n",
    " 720,\n",
    " 730,\n",
    " 734,\n",
    " 742,\n",
    " 744,\n",
    " 746,\n",
    " 747,\n",
    " 748,\n",
    " 759,\n",
    " 765,\n",
    " 768,\n",
    " 769,\n",
    " 774,\n",
    " 783,\n",
    " 784,\n",
    " 787,\n",
    " 788,\n",
    " 810,\n",
    " 812,\n",
    " 815,\n",
    " 817,\n",
    " 820,\n",
    " 825,\n",
    " 833,\n",
    " 836,\n",
    " 838,\n",
    " 862,\n",
    " 863,\n",
    " 879,\n",
    " 884,\n",
    " 900,\n",
    " 901,\n",
    " 912,\n",
    " 918,\n",
    " 926,\n",
    " 929,\n",
    " 940,\n",
    " 943,\n",
    " 949,\n",
    " 951,\n",
    " 961,\n",
    " 962,\n",
    " 974,\n",
    " 980,\n",
    " 996,\n",
    " 1011,\n",
    " 1016,\n",
    " 1017,\n",
    " 1018,\n",
    " 1034,\n",
    " 1037,\n",
    " 1043,\n",
    " 1044,\n",
    " 1053,\n",
    " 1058,\n",
    " 1065,\n",
    " 1081,\n",
    " 1090,\n",
    " 1093,\n",
    " 1097]\n",
    "\n",
    "# Filter DataFrame where ID is in the selected list\n",
    "subset_df = df[df['ID'].isin(training_ids)]\n",
    "subset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a0d390",
   "metadata": {},
   "source": [
    "### Features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1971516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz\n",
    "import jellyfish\n",
    "import Levenshtein\n",
    "\n",
    "pairs = []\n",
    "labels = []\n",
    "\n",
    "fullname_pairs = []\n",
    "firstname_pairs = []\n",
    "lastname_pairs = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(subset_df)):\n",
    "    id = subset_df['ID'].iloc[i]\n",
    "    for k in range(len(subset_df)):\n",
    "        if i != k:\n",
    "            fullname_pairs.append((subset_df['fullname'].iloc[i],subset_df['fullname'].iloc[k]))\n",
    "            firstname_pairs.append((subset_df['firstname'].iloc[i],subset_df['firstname'].iloc[k]))\n",
    "            lastname_pairs.append((subset_df['lastname'].iloc[i],subset_df['lastname'].iloc[k]))\n",
    "            if id == subset_df['ID'].iloc[k]:\n",
    "                labels.append(1)\n",
    "            else: \n",
    "                labels.append(0)\n",
    "                \n",
    "def check_first_letters(str1, str2):\n",
    "    def get_first_letters(s):\n",
    "        return sorted([word[0].lower() for word in s.split() if word])\n",
    "\n",
    "    first_letters1 = get_first_letters(str1)\n",
    "    first_letters2 = get_first_letters(str2)\n",
    "    \n",
    "    set1 = set(first_letters1)\n",
    "    set2 = set(first_letters2)\n",
    "\n",
    "    # Return True if they are equal or if one is a subset of the other\n",
    "    return set1 == set2 or set1.issubset(set2) or set2.issubset(set1)\n",
    "\n",
    "features = []\n",
    "for i in range(len(fullname_pairs)):\n",
    "\n",
    "    features.append({\n",
    "        'fullname_ratio': fuzz.ratio(fullname_pairs[i][0], fullname_pairs[i][1]),\n",
    "        'fullname_partial_ratio': fuzz.partial_ratio(fullname_pairs[i][0], fullname_pairs[i][1]),\n",
    "        'fullname_token_sort_ratio': fuzz.token_sort_ratio(fullname_pairs[i][0], fullname_pairs[i][1]),\n",
    "        'fullname_token_set_ratio': fuzz.token_set_ratio(fullname_pairs[i][0], fullname_pairs[i][1]),\n",
    "        'fullname_levenshtein': Levenshtein.distance(fullname_pairs[i][0], fullname_pairs[i][1]),\n",
    "        'fullname_jaro_winkler': jellyfish.jaro_winkler_similarity(fullname_pairs[i][0], fullname_pairs[i][1]),\n",
    "        'lastname_ratio':fuzz.ratio(lastname_pairs[i][0], lastname_pairs[i][1]),\n",
    "        'lastname_partial_ratio': fuzz.partial_ratio(lastname_pairs[i][0], lastname_pairs[i][1]),\n",
    "        'lastname_token_sort_ratio': fuzz.token_sort_ratio(lastname_pairs[i][0], lastname_pairs[i][1]),\n",
    "        'lastname_token_set_ratio': fuzz.token_set_ratio(lastname_pairs[i][0], lastname_pairs[i][1]),\n",
    "        'lastname_levenshtein': Levenshtein.distance(lastname_pairs[i][0], lastname_pairs[i][1]),\n",
    "        'lastname_jaro_winkler': jellyfish.jaro_winkler_similarity(lastname_pairs[i][0], lastname_pairs[i][1]),\n",
    "        'firstname_ratio':fuzz.ratio(firstname_pairs[i][0], firstname_pairs[i][1]),\n",
    "        'firstname_partial_ratio': fuzz.partial_ratio(firstname_pairs[i][0], firstname_pairs[i][1]),\n",
    "        'firstname_token_sort_ratio': fuzz.token_sort_ratio(firstname_pairs[i][0], firstname_pairs[i][1]),\n",
    "        'firstname_token_set_ratio': fuzz.token_set_ratio(firstname_pairs[i][0], firstname_pairs[i][1]),\n",
    "        'firstname_levenshtein': Levenshtein.distance(firstname_pairs[i][0], firstname_pairs[i][1]),\n",
    "        'firstname_jaro_winkler': jellyfish.jaro_winkler_similarity(firstname_pairs[i][0], firstname_pairs[i][1]),\n",
    "    })\n",
    "\n",
    "X = pd.DataFrame(features)\n",
    "y = pd.Series(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a513bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train model\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41733ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pairs_fullname = []\n",
    "new_pairs_firstname = []\n",
    "new_pairs_lastname = []\n",
    "new_labels = []\n",
    "indexes = [] \n",
    "\n",
    "def check_first_letters(str1, str2):\n",
    "    def get_first_letters(s):\n",
    "        return sorted([word[0].lower() for word in s.split() if word])\n",
    "\n",
    "    first_letters1 = get_first_letters(str1)\n",
    "    first_letters2 = get_first_letters(str2)\n",
    "    \n",
    "    set1 = set(first_letters1)\n",
    "    set2 = set(first_letters2)\n",
    "\n",
    "    # Return True if they are equal or if one is a subset of the other\n",
    "    return set1 == set2 or set1.issubset(set2) or set2.issubset(set1)\n",
    "\n",
    "fullnames = df['fullname'].values\n",
    "firstnames = df['firstname'].values\n",
    "lastnames = df['lastname'].values\n",
    "ids = df['ID'].values\n",
    "index = df['Index'].values\n",
    "for i in range(len(df)):\n",
    "    id = ids[i]\n",
    "    for k in range(len(df)):\n",
    "        if i != k:\n",
    "            new_pairs_fullname.append((fullnames[i],fullnames[k]))\n",
    "            new_pairs_firstname.append((firstnames[i],firstnames[k]))\n",
    "            new_pairs_lastname.append((lastnames[i],lastnames[k]))\n",
    "            indexes.append((index[i],index[k]))\n",
    "            if id == ids[k]:\n",
    "                new_labels.append(1)\n",
    "            else: \n",
    "                new_labels.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89ad537",
   "metadata": {},
   "source": [
    "### Pair-wise evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602ad07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "new_features = pd.DataFrame([{\n",
    "    'fullname_ratio': fuzz.ratio(new_pairs_fullname[i][0], new_pairs_fullname[i][1]),\n",
    "    'fullname_partial_ratio': fuzz.partial_ratio(new_pairs_fullname[i][0], new_pairs_fullname[i][1]),\n",
    "    'fullname_token_sort_ratio': fuzz.token_sort_ratio(new_pairs_fullname[i][0], new_pairs_fullname[i][1]),\n",
    "    'fullname_token_set_ratio': fuzz.token_set_ratio(new_pairs_fullname[i][0], new_pairs_fullname[i][1]),\n",
    "    'fullname_levenshtein': Levenshtein.distance(new_pairs_fullname[i][0], new_pairs_fullname[i][1]),\n",
    "    'fullname_jaro_winkler': jellyfish.jaro_winkler_similarity(new_pairs_fullname[i][0], new_pairs_fullname[i][1]),\n",
    "    'lastname_ratio':fuzz.ratio(new_pairs_lastname[i][0], new_pairs_lastname[i][1]),\n",
    "    'lastname_partial_ratio': fuzz.partial_ratio(new_pairs_lastname[i][0], new_pairs_lastname[i][1]),\n",
    "    'lastname_token_sort_ratio': fuzz.token_sort_ratio(new_pairs_lastname[i][0], new_pairs_lastname[i][1]),\n",
    "    'lastname_token_set_ratio': fuzz.token_set_ratio(new_pairs_lastname[i][0], new_pairs_lastname[i][1]),\n",
    "    'lastname_levenshtein': Levenshtein.distance(new_pairs_lastname[i][0], new_pairs_lastname[i][1]),\n",
    "    'lastname_jaro_winkler': jellyfish.jaro_winkler_similarity(new_pairs_lastname[i][0], new_pairs_lastname[i][1]),\n",
    "    'firstname_ratio':fuzz.ratio(new_pairs_firstname[i][0], new_pairs_firstname[i][1]),\n",
    "    'firstname_partial_ratio': fuzz.partial_ratio(new_pairs_firstname[i][0], new_pairs_firstname[i][1]),\n",
    "    'firstname_token_sort_ratio': fuzz.token_sort_ratio(new_pairs_firstname[i][0], new_pairs_firstname[i][1]),\n",
    "    'firstname_token_set_ratio': fuzz.token_set_ratio(new_pairs_firstname[i][0], new_pairs_firstname[i][1]),\n",
    "    'firstname_levenshtein': Levenshtein.distance(new_pairs_firstname[i][0], new_pairs_firstname[i][1]),\n",
    "    'firstname_jaro_winkler': jellyfish.jaro_winkler_similarity(new_pairs_firstname[i][0], new_pairs_firstname[i][1]),\n",
    "} for i in range(len(new_pairs_fullname))])\n",
    "\n",
    "predictions = model.predict_proba(new_features)[:, 1]\n",
    "best_f1 = 0\n",
    "best_threshold = None\n",
    "\n",
    "for i in range(50,91):\n",
    "    prediction = [1 if pred > i/100 else 0 for pred in predictions]\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(new_labels, prediction, average='binary')\n",
    "        \n",
    "    print(f\"{i} : {precision:9.2f} | {recall:6.2f} | {f1:4.2f}\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = i\n",
    "\n",
    "print(f\"\\nBest threshold : {best_threshold} with F1 score: {best_f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f848076",
   "metadata": {},
   "source": [
    "### Cluster-level evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b09d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "def get_cluster_evaluation(df):\n",
    "    y_pred = []\n",
    "    y_truth = []\n",
    "    groups = df['Cluster_graph'].values\n",
    "    ids = df['ID'].values\n",
    "    for i in range(len(df)):\n",
    "        for k in range(len(df)):\n",
    "            if i != k:\n",
    "                if groups[i] == groups[k]:\n",
    "                    y_pred.append(1)\n",
    "                else:\n",
    "                    y_pred.append(0)\n",
    "            if i != k:\n",
    "                if ids[i] == ids[k]:\n",
    "                    y_truth.append(1)\n",
    "                else:\n",
    "                    y_truth.append(0)\n",
    "    return y_pred,y_truth\n",
    "\n",
    "group = [[] for _ in range(len(df))]\n",
    "prediction = [1 if pred > 50/100 else 0 for pred in predictions]\n",
    "for i in range(len(new_labels)):\n",
    "    if prediction[i] == 1:\n",
    "        group[indexes[i][0]].append(indexes[i][1])\n",
    "df['GROUP'] = group\n",
    "\n",
    "\n",
    "y_pred,y_truth = get_cluster_evaluation(df)\n",
    "\n",
    "precision = precision_score(y_truth, y_pred)\n",
    "recall    = recall_score(y_truth, y_pred)\n",
    "f1        = f1_score(y_truth, y_pred)\n",
    "accuracy  = accuracy_score(y_truth, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall   : {recall:.2f}\")\n",
    "print(f\"F1 Score : {f1:.2f}\")\n",
    "print(f\"Accuracy : {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fdb4df",
   "metadata": {},
   "source": [
    "# Phonetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e8992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('phonetic_name_matching_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff401c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ids = [2,6,9,12,14]\n",
    "# Filter DataFrame where ID is in the selected list\n",
    "subset_df = df[df['ID'].isin(training_ids)]\n",
    "subset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca8b84d",
   "metadata": {},
   "source": [
    "### Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c744e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz\n",
    "import jellyfish\n",
    "import Levenshtein\n",
    "import os\n",
    "\n",
    "pairs = []\n",
    "labels = []\n",
    "\n",
    "fullname_pairs = []\n",
    "firstname_pairs = []\n",
    "lastname_pairs = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(subset_df)):\n",
    "    id = subset_df['ID'].iloc[i]\n",
    "    for k in range(len(subset_df)):\n",
    "        if i != k:\n",
    "            fullname_pairs.append((subset_df['fullname'].iloc[i],subset_df['fullname'].iloc[k]))\n",
    "            firstname_pairs.append((subset_df['firstname'].iloc[i],subset_df['firstname'].iloc[k]))\n",
    "            lastname_pairs.append((subset_df['lastname'].iloc[i],subset_df['lastname'].iloc[k]))\n",
    "            if id == subset_df['ID'].iloc[k]:\n",
    "                labels.append(1)\n",
    "            else: \n",
    "                labels.append(0)\n",
    "                \n",
    "def check_first_letters(str1, str2):\n",
    "    def get_first_letters(s):\n",
    "        return sorted([word[0].lower() for word in s.split() if word])\n",
    "\n",
    "    first_letters1 = get_first_letters(str1)\n",
    "    first_letters2 = get_first_letters(str2)\n",
    "    \n",
    "    set1 = set(first_letters1)\n",
    "    set2 = set(first_letters2)\n",
    "\n",
    "    # Return True if they are equal or if one is a subset of the other\n",
    "    return set1 == set2 or set1.issubset(set2) or set2.issubset(set1)\n",
    "\n",
    "features = []\n",
    "for i in range(len(fullname_pairs)):\n",
    "\n",
    "    features.append({\n",
    "        'fdist': jellyfish.jaro_winkler_similarity(firstname_pairs[i][0], firstname_pairs[i][1]),\n",
    "        'ldist': jellyfish.jaro_winkler_similarity(lastname_pairs[i][0], lastname_pairs[i][1]),\n",
    "\n",
    "        'exact': int(firstname_pairs[i][0] == firstname_pairs[i][1] and lastname_pairs[i][0] == lastname_pairs[i][1]),\n",
    "\n",
    "        'f_start': int(bool(firstname_pairs[i][0]) and bool(firstname_pairs[i][1]) and firstname_pairs[i][0][0] == firstname_pairs[i][1][0]),\n",
    "        'f_end': int(bool(firstname_pairs[i][0]) and bool(firstname_pairs[i][1]) and firstname_pairs[i][0][-1] == firstname_pairs[i][1][-1]),\n",
    "        'l_start': int(bool(lastname_pairs[i][0]) and bool(lastname_pairs[i][1]) and lastname_pairs[i][0][0] == lastname_pairs[i][1][0]),\n",
    "        'l_end': int(bool(lastname_pairs[i][0]) and bool(lastname_pairs[i][1]) and lastname_pairs[i][0][-1] == lastname_pairs[i][1][-1]),\n",
    "\n",
    "        'fsoundex': int(jellyfish.soundex(firstname_pairs[i][0]) == jellyfish.soundex(firstname_pairs[i][1])),\n",
    "        'lsoundex': int(jellyfish.soundex(lastname_pairs[i][0]) == jellyfish.soundex(lastname_pairs[i][1])),\n",
    "    })\n",
    "\n",
    "X = pd.DataFrame(features)\n",
    "y = pd.Series(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672682a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train model\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13815c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pairs_fullname = []\n",
    "new_pairs_firstname = []\n",
    "new_pairs_lastname = []\n",
    "new_labels = []\n",
    "indexes = [] \n",
    "\n",
    "def check_first_letters(str1, str2):\n",
    "    def get_first_letters(s):\n",
    "        return sorted([word[0].lower() for word in s.split() if word])\n",
    "\n",
    "    first_letters1 = get_first_letters(str1)\n",
    "    first_letters2 = get_first_letters(str2)\n",
    "    \n",
    "    set1 = set(first_letters1)\n",
    "    set2 = set(first_letters2)\n",
    "\n",
    "    # Return True if they are equal or if one is a subset of the other\n",
    "    return set1 == set2 or set1.issubset(set2) or set2.issubset(set1)\n",
    "\n",
    "fullnames = df['fullname'].values\n",
    "firstnames = df['firstname'].values\n",
    "lastnames = df['lastname'].values\n",
    "ids = df['ID'].values\n",
    "index = df['Index'].values\n",
    "for i in range(len(df)):\n",
    "    id = ids[i]\n",
    "    for k in range(len(df)):\n",
    "        if i != k:\n",
    "            new_pairs_fullname.append((fullnames[i],fullnames[k]))\n",
    "            new_pairs_firstname.append((firstnames[i],firstnames[k]))\n",
    "            new_pairs_lastname.append((lastnames[i],lastnames[k]))\n",
    "            indexes.append((index[i],index[k]))\n",
    "            if id == ids[k]:\n",
    "                new_labels.append(1)\n",
    "            else: \n",
    "                new_labels.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ec84b7",
   "metadata": {},
   "source": [
    "### Pair-wise evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d3671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "new_features = pd.DataFrame([{\n",
    "    'fdist': jellyfish.jaro_winkler_similarity(firstname_pairs[i][0], firstname_pairs[i][1]),\n",
    "    'ldist': jellyfish.jaro_winkler_similarity(lastname_pairs[i][0], lastname_pairs[i][1]),\n",
    "\n",
    "    'exact': int(firstname_pairs[i][0] == firstname_pairs[i][1] and lastname_pairs[i][0] == lastname_pairs[i][1]),\n",
    "\n",
    "    'f_start': int(bool(firstname_pairs[i][0]) and bool(firstname_pairs[i][1]) and firstname_pairs[i][0][0] == firstname_pairs[i][1][0]),\n",
    "    'f_end': int(bool(firstname_pairs[i][0]) and bool(firstname_pairs[i][1]) and firstname_pairs[i][0][-1] == firstname_pairs[i][1][-1]),\n",
    "    'l_start': int(bool(lastname_pairs[i][0]) and bool(lastname_pairs[i][1]) and lastname_pairs[i][0][0] == lastname_pairs[i][1][0]),\n",
    "    'l_end': int(bool(lastname_pairs[i][0]) and bool(lastname_pairs[i][1]) and lastname_pairs[i][0][-1] == lastname_pairs[i][1][-1]),\n",
    "\n",
    "    'fsoundex': int(jellyfish.soundex(firstname_pairs[i][0]) == jellyfish.soundex(firstname_pairs[i][1])),\n",
    "    'lsoundex': int(jellyfish.soundex(lastname_pairs[i][0]) == jellyfish.soundex(lastname_pairs[i][1])),\n",
    "} for i in range(len(new_pairs_fullname))])\n",
    "\n",
    "predictions = model.predict_proba(new_features)[:, 1]\n",
    "best_f1 = 0\n",
    "best_threshold = None\n",
    "\n",
    "for i in range(50,91):\n",
    "    prediction = [1 if pred > i/100 else 0 for pred in predictions]\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(new_labels, prediction, average='binary')\n",
    "        \n",
    "    print(f\"{i} : {precision:9.2f} | {recall:6.2f} | {f1:4.2f}\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = i\n",
    "\n",
    "print(f\"\\nBest threshold : {best_threshold} with F1 score: {best_f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0396ab",
   "metadata": {},
   "source": [
    "### Cluster-level evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d559576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "def get_cluster_evaluation(df):\n",
    "    y_pred = []\n",
    "    y_truth = []\n",
    "    groups = df['Cluster_graph'].values\n",
    "    ids = df['ID'].values\n",
    "    for i in range(len(df)):\n",
    "        for k in range(len(df)):\n",
    "            if i != k:\n",
    "                if groups[i] == groups[k]:\n",
    "                    y_pred.append(1)\n",
    "                else:\n",
    "                    y_pred.append(0)\n",
    "            if i != k:\n",
    "                if ids[i] == ids[k]:\n",
    "                    y_truth.append(1)\n",
    "                else:\n",
    "                    y_truth.append(0)\n",
    "    return y_pred,y_truth\n",
    "\n",
    "group = [[] for _ in range(len(df))]\n",
    "prediction = [1 if pred > 50/100 else 0 for pred in predictions]\n",
    "for i in range(len(new_labels)):\n",
    "    if prediction[i] == 1:\n",
    "        group[indexes[i][0]].append(indexes[i][1])\n",
    "df['GROUP'] = group\n",
    "\n",
    "\n",
    "y_pred,y_truth = get_cluster_evaluation(df)\n",
    "\n",
    "precision = precision_score(y_truth, y_pred)\n",
    "recall    = recall_score(y_truth, y_pred)\n",
    "f1        = f1_score(y_truth, y_pred)\n",
    "accuracy  = accuracy_score(y_truth, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall   : {recall:.2f}\")\n",
    "print(f\"F1 Score : {f1:.2f}\")\n",
    "print(f\"Accuracy : {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
